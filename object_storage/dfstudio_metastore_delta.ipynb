{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d284dbe",
   "metadata": {},
   "source": [
    "### **Data Flow Studio + Delta Table + Metastore**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd69fa5",
   "metadata": {},
   "source": [
    "##### Setup Data Flow Studio Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b948310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "ads.set_auth(\"resource_principal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "compartment_id = os.environ.get(\"NB_SESSION_COMPARTMENT_OCID\") # identificando o compartimento da OCI em utilização\n",
    "logs_bucket_uri = \"oci://bucket_name@namespace\" # definindo o bucket para armazenamento de logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14da792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def prepare_command(command: dict) -> str:\n",
    "    \"\"\"Converts dictionary command to the string formatted commands.\"\"\"\n",
    "    return f\"'{json.dumps(command)}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dataflow.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eeab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d2291",
   "metadata": {},
   "source": [
    "##### Create a new Data Flow Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f927c211",
   "metadata": {},
   "source": [
    "documentation: https://docs.oracle.com/en-us/iaas/data-flow/using/data-flow-studio.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34040e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%create_session -l python -c '{\\\n",
    "        \"compartmentId\": \"ocid1.compartment.oc1........a\",\\\n",
    "        \"displayName\": \"DataFlow Studio Name\",\\\n",
    "        \"language\": \"PYTHON\",\\\n",
    "        \"sparkVersion\": \"3.2.1\",\\\n",
    "        \"numExecutors\": 1,\\\n",
    "        \"driverShape\": \"VM.Standard.E4.Flex\",\\\n",
    "        \"executorShape\": \"VM.Standard.E4.Flex\",\\\n",
    "        \"driverShapeConfig\": {\"ocpus\": 1, \"memoryInGBs\": 16},\\\n",
    "        \"executorShapeConfig\": {\"ocpus\": 1, \"memoryInGBs\": 16},\\\n",
    "        \"logsBucketUri\": \"oci://bucket_name@namespace\",\\\n",
    "        \"configuration\":{\\\n",
    "          \"spark.archives\": \"bucket_name@namespace/conda_environments_path#conda\",\\\n",
    "          \"metastoreId\":\"ocid1.datacatalogmetastore..........3xa\",\\\n",
    "          \"spark.oracle.datasource.enabled\":\"true\"\\\n",
    "          \"privateEndpointId\":\"ocid1.dataflowprivateendpoint..........aifq\"}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6108e8c9",
   "metadata": {},
   "source": [
    "##### Use a existing Data Flow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0011597",
   "metadata": {},
   "outputs": [],
   "source": [
    "%use_session -s {'ocid1.dataflowapplication........5vq'} -f"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27861b3b",
   "metadata": {},
   "source": [
    "%config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "print(f'A versão do Spark em execução no cluster do Data Flow Studio é: {sc.version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa304518",
   "metadata": {},
   "source": [
    "### **Work with files in OCI Object Storage - Buckets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a10cbd9",
   "metadata": {},
   "source": [
    "#### Read .csv files from OCI Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360412c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Path to csv file\n",
    "csv_file = \"oci://bucket_name@namespace/file_name.csv\"\n",
    "\n",
    "# Read csv file to dataframe\n",
    "df_vendas = spark.read.csv(csv_file, header=True, inferSchema=True)\n",
    "df_vendas.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6cf530",
   "metadata": {},
   "source": [
    "#### Create Temporary View using a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c675deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "df.createOrReplaceTempView(\"view_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73639148",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql\n",
    "describe view_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf42bb75",
   "metadata": {},
   "source": [
    "#### Query the Temp View with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql\n",
    "SELECT * FROM view_name LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1df05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql\n",
    "SELECT * FROM view_name LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c44378",
   "metadata": {},
   "source": [
    "#### Write .csv files from OCI Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Path to csv file\n",
    "csv_file_path = \"bucket_name@namespace\" \n",
    "\n",
    "# Escrever no bucket em CSV\n",
    "df_transformed.write.csv(csv_file_path, mode=\"overwrite\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9100250",
   "metadata": {},
   "source": [
    "### **Work with Metastore Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql\n",
    "-- create database\n",
    "CREATE DATABASE <DATABASE_NAME>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed80291",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql\n",
    "-- create table from select\n",
    "CREATE TABLE <DATABASE_NAME>.view_name AS SELECT * FROM table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee1ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql\n",
    "USE <DATABASE_NAME>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql\n",
    "SHOW TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0ea463",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql\n",
    "SHOW DATABASES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea810caa",
   "metadata": {},
   "source": [
    "#### Using SQL with Metastore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql\n",
    "SELECT * FROM <DATABASE_NAME>.table_name LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd935500",
   "metadata": {},
   "source": [
    "#### Read CSV files from OCI Object Storage and write in Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ef245",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Path to csv file\n",
    "csv_file = \"oci://bucket_name@namespace/file_name.csv\"\n",
    "\n",
    "# Read csv file to dataframe\n",
    "df_file = spark.read.csv(csv_file, header=True, inferSchema=True)\n",
    "\n",
    "# Write data from a dataframe to a bucket in Delta Table\n",
    "df_file.write.format(\"delta\").mode(\"overwrite\").save(\"oci://bucket_name@namespace/destination_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1d67bb",
   "metadata": {},
   "source": [
    "#### Read JSON files from OCI Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc75959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Read JSON file from OCI Object Storage Bucket\n",
    "json_file = \"oci://bucket_name@namespace/file_name.json\"\n",
    "df_json = spark.read.option(\"multiline\", \"true\").json(json_file)\n",
    "\n",
    "# Check JSON\n",
    "df_json.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aca5fc",
   "metadata": {},
   "source": [
    "#### Read PARQUET files from OCI Object Storage and write in Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c77e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "# Path to parquet file\n",
    "parquet_file = \"oci://bucket_name@namespace/file_name\"\n",
    "\n",
    "# Read parquet file to dataframe\n",
    "df_clientes = spark.read.parquet(parquet_file)\n",
    "\n",
    "# Write data from a dataframe to a bucket in Delta Table\n",
    "df_clientes.write.format(\"delta\").mode(\"overwrite\").save(\"oci://bucket_name@namespace/destination_name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark32_p38_cpu_v3]",
   "language": "python",
   "name": "conda-env-pyspark32_p38_cpu_v3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
